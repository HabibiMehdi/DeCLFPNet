# LFPRegNet 
This is first version of my code for LFPRegNet that paper will be publish in ieee transaction on industrial informatics 
author : mehdi habibi 
 3 december 2024 

## 1. Problem Statement

## 2. Related Works
                                                                                     	| Code                                                                              	|
|------	|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|-----------------------------------------------------------------------------------	|
| 2017 	| [Attention Is All You Need](https://arxiv.org/abs/1706.03762v7)<br>The paper introduces a architecture called Transformer. It is an architecture for transforming one sequence into another one with the help of two parts (Encoder and Decoder). Transformer uses the attention-mechanism. The attention-mechanism looks at an input sequence and decides at each step which other parts of the sequence are important                                                                                       	| [Link](https://github.com/huggingface/transformers)                               	|
| 2020 	| [Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100)<br>The paper proposes the convolution-augmented transformer for speech recognition, named Conformer. Transformer models are good at capturing content-based global interactions, while CNNs exploit local features effectively. In this work, they combine convolution neural networks and transformers to model both local and global dependencies of an audio sequence in a parameter-efficient way. 	| [Link](https://pytorch.org/audio/main/generated/torchaudio.models.Conformer.html) 	|
| 2020 	| [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/pdf/2006.11477v3.pdf)<br>Wav2Vec 2.0 uses a self-supervised training approach for Automatic Speech Recognition, which is based on the idea of contrastive learning. It learns speech representations on unlabeled data.                                                                                                                                                                                       	| [Link](https://github.com/facebookresearch/fairseq)                               	|
| 2022 	| [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/pdf/2212.04356.pdf)<br>Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.                                                                                                                                                                	| [Link](https://github.com/openai/whisper)                                         	|

## 3. The Proposed Method
   
## 4. Implementation
   
### 4.1. Dataset
This datasets contain three rats , this data was recorded by khorasani ,2016

### 4.2. Model
### 4.3. Configurations
### 4.4. Train
### 4.5. Evaluate
   

